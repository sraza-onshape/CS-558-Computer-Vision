{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "Name: Syed Zain Raza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building-Only Images: `entry-P10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = \"./SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008\"\n",
    "subset_names1 = [\"entry-P10\"]\n",
    "file_ext_pattern = \"*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_image_paths(\n",
    "    base_data_path: str,\n",
    "    image_subset_paths: List[str],\n",
    "    file_ext_pattern: str,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Look up all the images we care about using a file paths pattern. \n",
    "    Returns the file paths in a 1D Python list.\n",
    "    \"\"\"\n",
    "    all_img_paths = list()\n",
    "\n",
    "    for subset in image_subset_paths:\n",
    "        pattern_for_subset_images = \"/\".join(\n",
    "            [base_data_path, subset, \"images\", file_ext_pattern]\n",
    "        )\n",
    "        all_img_paths.extend(glob.glob(pattern_for_subset_images))\n",
    "\n",
    "    return all_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_building_only_img_paths = aggregate_image_paths(BASE_DATA_PATH, subset_names1, file_ext_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0006.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0007.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0005.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0004.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0000.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0001.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0003.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0002.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0009.jpg',\n",
       " './SfM_quality_evaluation/Benchmarking_Camera_Calibration_2008/entry-P10/images/0008.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_building_only_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_only_img_arrays = [\n",
    "    ops.load_image(\n",
    "        img_path,\n",
    "        return_grayscale=False,\n",
    "        return_array=True,  # dictates that we want to have a NumPy array\n",
    "        verbosity=False,\n",
    "    )\n",
    "    for img_path in ten_building_only_img_paths\n",
    "]\n",
    "# for convenience\n",
    "building_only_img_map = dict(zip(ten_building_only_img_paths, building_only_img_arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Tractor Images\n",
    "\n",
    "- let `castle-P30` = \"training\" images for the framework\n",
    "- let `castle-P19` = \"hold-out\" images in the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = aggregate_image_paths(\n",
    "    BASE_DATA_PATH, [\"castle-P30\"], file_ext_pattern\n",
    ")\n",
    "\n",
    "test_img_paths = aggregate_image_paths(\n",
    "    BASE_DATA_PATH, [\"castle-P19\"], file_ext_pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = [\n",
    "    ops.load_image(\n",
    "        img_path,\n",
    "        return_grayscale=False,\n",
    "        return_array=True,  # dictates that we want to have a NumPy array\n",
    "        verbosity=False,\n",
    "    )\n",
    "    for img_path in train_img_paths\n",
    "]\n",
    "# for convenience\n",
    "train_img_map = dict(zip(train_img_paths, train_img_arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_arrays = [\n",
    "    ops.load_image(\n",
    "        img_path,\n",
    "        return_grayscale=False,\n",
    "        return_array=True,  # dictates that we want to have a NumPy array\n",
    "        verbosity=False,\n",
    "    )\n",
    "    for img_path in test_img_paths\n",
    "]\n",
    "# for convenience\n",
    "test_img_map = dict(zip(test_img_paths, test_img_arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from util.clustering import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Goal is for us to have a trained estimator that, when given a set of pixel-wise features of an image, can produce a binary mask we can use for segmenting out our tractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get features. For now, stick to simple RGB space\n",
    "def _reshape_into_3d(img: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        pixels = np.zeros((img.shape[1] * img.shape[0], 3))\n",
    "        pixel_index = 0\n",
    "        for x in np.arange(img.shape[1]):\n",
    "            for y in np.arange(img.shape[0]):\n",
    "                pixels[pixel_index] = img[y, x, :]\n",
    "                pixel_index += 1\n",
    "        \n",
    "        return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_img_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_building_and_tractor_features = list(map(_reshape_into_3d, train_img_arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_building_only_features = list(map(_reshape_into_3d, building_only_img_arrays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Clustering the Building Only Images\n",
    "\n",
    "We use mean shift clustering, as we want an unbiased picture on how closely clustered the features of the building tend to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mean_shift(\n",
    "    data: np.ndarray,\n",
    "    window_size: int = 1.0,\n",
    "    max_iter: int = 100,\n",
    "    convergence_threshold: float = 1e-4,\n",
    ") -> Dict[int, Tuple[Tuple[float], List[np.ndarray]]]:\n",
    "    \"\"\"\n",
    "    Unsupervised clustering of n-dimensional feature vectors using Mean-Shift.\n",
    "    Returns a dictionary in the form: {cluster_label -> (cluster_centroid_coords, list_of_member_img_indices)}.\n",
    "    \"\"\"\n",
    "    # 1: find the \"hill\" each point should climb\n",
    "    n_points = data.shape[0]\n",
    "\n",
    "    # Initialize random means for each data point\n",
    "    hills = list()\n",
    "\n",
    "    for i in range(n_points):\n",
    "        current_point = data[i, :]\n",
    "        means = [current_point]\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # Find points within the bandwidth distance from the current mean\n",
    "            last_mean = means[-1]\n",
    "            within_window = np.linalg.norm(data - last_mean, axis=1) < window_size\n",
    "\n",
    "            # Update mean using the points within the bandwidth\n",
    "            new_mean = np.mean(data[within_window], axis=0)\n",
    "            means.append(new_mean)\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(last_mean - new_mean) < convergence_threshold:\n",
    "                break\n",
    "\n",
    "        hills.append(means)\n",
    "\n",
    "    # 2: Assign cluster labels based on the final means\n",
    "    unique_means = list(set([tuple(hill[-1]) for hill in hills]))\n",
    "    cluster_labels_to_points = dict()\n",
    "    cluster_coords_to_labels = dict()\n",
    "    for cluster_label in range(len(unique_means)):\n",
    "        cluster_labels_to_points[cluster_label] = list()\n",
    "        cluster_coords_to_labels[unique_means[cluster_label]] = cluster_label\n",
    "\n",
    "    for i, hill in enumerate(hills):\n",
    "        # map this point to the specific cluster\n",
    "        mean = hill[-1]\n",
    "        original_point = hill[0]\n",
    "        label = cluster_coords_to_labels[tuple(mean)]\n",
    "        cluster_labels_to_points[label].append(i)\n",
    "\n",
    "    # bring it all together: label -> centroid, list of original pts\n",
    "    all_cluster_data = dict()\n",
    "    for centroid_coords, label in cluster_coords_to_labels.items():\n",
    "        original_pts = cluster_labels_to_points[label]\n",
    "        all_cluster_data[label] = (centroid_coords, original_pts)\n",
    "\n",
    "    return all_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_report_clusters(\n",
    "    data: np.ndarray,\n",
    "    window_size: int = 1.0,\n",
    "    max_iter: int = 100,\n",
    "    convergence_threshold: float = 1e-4,\n",
    ") -> Dict[int, Tuple[Tuple[float], List[np.ndarray]]]:\n",
    "    \"\"\"Convenience wrapper around mean shift function.\"\"\"\n",
    "    clusters_of_descriptors = mean_shift(\n",
    "        data=data,\n",
    "        window_size=500,\n",
    "        max_iter=1_000_000_0,\n",
    "        convergence_threshold=1.5,\n",
    "    )\n",
    "\n",
    "    for label, pair in clusters_of_descriptors.items():\n",
    "        print(\"==========================\")\n",
    "        print(f\"Cluster #{label + 1} Report:\")\n",
    "        print(f\"Centroid Coordinates: {pair[0]}\")\n",
    "        print(f\"Cluster Members (by Image Index): {pair[1]}\")\n",
    "\n",
    "    return clusters_of_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6291456, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_img_building_only_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_of_building_only_rgb_features = compute_and_report_clusters(\n",
    "    data=np.array(train_img_building_only_features)[0, :, :],\n",
    "    window_size=500,\n",
    "    max_iter=1_000_000_0,\n",
    "    convergence_threshold=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end-env",
   "language": "python",
   "name": "end-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
